# ğŸ¦ ETL Pipeline - Transacciones Bancarias con Databricks

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python](https://img.shields.io/badge/Python-3.11%2B-blue)](https://www.python.org/downloads/)
[![Databricks](https://img.shields.io/badge/Databricks-Latest-brightgreen)](https://databricks.com/)

## ğŸ“– DescripciÃ³n

Pipeline de ETL (Extract, Transform, Load) profesional para procesar transacciones bancarias multimoneda utilizando **Apache Spark**, **Databricks**, y **Delta Lake**. El proyecto automatiza la ingestiÃ³n, transformaciÃ³n y anÃ¡lisis de datos financieros, generando una tabla de hechos optimizada para business intelligence.

### CaracterÃ­sticas Principales
âœ… Procesamiento de transacciones multimoneda (USD, BolÃ­vares)  
âœ… ConversiÃ³n automÃ¡tica de monedas  
âœ… NormalizaciÃ³n de datos de clientes  
âœ… Tabla Delta optimizada para anÃ¡lisis  
âœ… Escalable a millones de registros  
âœ… DocumentaciÃ³n completa y cÃ³digo modular  

---

## ğŸ—ï¸ Arquitectura del Proyecto

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Transacciones CSV  â”‚
â”‚  (Clientes JSON)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Spark ETL Layer    â”‚
â”‚  â”œâ”€ Read CSV/JSON    â”‚
â”‚  â”œâ”€ Data Cleaning    â”‚
â”‚  â””â”€ Normalization    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Transformations     â”‚
â”‚  â”œâ”€ Currency Conv.   â”‚
â”‚  â”œâ”€ Aggregations     â”‚
â”‚  â””â”€ Date Processing  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Delta Lake         â”‚
â”‚ FactTransacciones    â”‚
â”‚  (Optimized Table)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BI & Analytics      â”‚
â”‚  SQL Queries         â”‚
â”‚  Dashboards          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Stack TecnolÃ³gico

| Componente | VersiÃ³n | PropÃ³sito |
|---|---|---|
| **Databricks** | Latest | Plataforma cloud de datos |
| **Apache Spark** | 3.x | Motor de procesamiento |
| **Delta Lake** | Latest | Storage optimizado |
| **Python** | 3.11+ | Lenguaje de scripting |
| **SQL** | ANSI | Transformaciones avanzadas |

---

## ğŸ“ Estructura del Repositorio

```
databricks-banking-etl/
â”œâ”€â”€ README.md                          # Este archivo
â”œâ”€â”€ LICENSE                            # Licencia MIT
â”œâ”€â”€ .gitignore                         # Excepciones de Git
â”œâ”€â”€ notebooks/                         # Notebooks de Databricks
â”‚   â”œâ”€â”€ 01_load_transactions.py       # Carga de transacciones
â”‚   â”œâ”€â”€ 02_load_customers.py          # Carga de clientes
â”‚   â”œâ”€â”€ 03_transformations.py         # Transformaciones
â”‚   â””â”€â”€ 04_fact_table.py              # GeneraciÃ³n de tabla de hechos
â”œâ”€â”€ sql/                               # Scripts SQL
â”‚   â”œâ”€â”€ create_schema.sql             # CreaciÃ³n de esquema
â”‚   â”œâ”€â”€ queries_analysis.sql          # Queries de anÃ¡lisis
â”‚   â””â”€â”€ views.sql                     # Vistas Ãºtiles
â”œâ”€â”€ data/                              # Datos de ejemplo
â”‚   â”œâ”€â”€ sample_transactions.csv       # Datos de prueba
â”‚   â”œâ”€â”€ sample_customers.json         # Clientes de prueba
â”‚   â””â”€â”€ README_DATA.md                # DocumentaciÃ³n de datos
â”œâ”€â”€ docs/                              # DocumentaciÃ³n tÃ©cnica
â”‚   â”œâ”€â”€ ARCHITECTURE.md               # DiseÃ±o de arquitectura
â”‚   â”œâ”€â”€ ETL_FLOW.md                   # Flujo ETL detallado
â”‚   â””â”€â”€ TROUBLESHOOTING.md            # GuÃ­a de soluciÃ³n de problemas
â””â”€â”€ config/                            # Configuraciones
    â”œâ”€â”€ settings.py                   # Variables globales
    â””â”€â”€ connections.py                # Conexiones a BD
```

---

## ğŸš€ Quick Start

### Requisitos Previos
- Cuenta activa en Databricks
- Cluster Databricks con Runtime 13.x+
- Datos en formato CSV y JSON

### 1. Clonar el Repositorio
```bash
git clone https://github.com/jeyssonlza/databricks-banking-etl.git
cd databricks-banking-etl
```

### 2. Configurar Notebook en Databricks
```python
# 1. Importar los notebooks desde GitHub
# 2. Actualizar rutas de datos segÃºn tu ambiente
# 3. Ejecutar secuencialmente: 01 â†’ 02 â†’ 03 â†’ 04
```

### 3. Validar Resultados
```sql
SELECT COUNT(*) as total_transacciones FROM proyecto_bancario.FactTransacciones;
SELECT * FROM proyecto_bancario.FactTransacciones LIMIT 10;
```

---

## ğŸ“Š Flujo de Datos

### Etapa 1: ExtracciÃ³n (Extract)
- **CSV de Transacciones**: Lectura con delimitador `|`
- **JSON de Clientes**: Lectura con modo multiline
- Validaciones de integridad

### Etapa 2: TransformaciÃ³n (Transform)
```python
# ConversiÃ³n de monedas
monto_BOLIVARES = WHEN moneda="USD" THEN monto * 4.5 ELSE monto

# NormalizaciÃ³n de documentos
documento = LPAD(documento, 8, '0')

# Agregaciones por usuario/dÃ­a
DEPOSITO = SUM(WHEN tipo_transaccion='DEPOSITO')
RETIRO = SUM(WHEN tipo_transaccion='RETIRO')
```

### Etapa 3: Carga (Load)
- Almacenamiento en Delta Lake
- Particionamiento por fecha
- Ãndices y optimizaciones

---

## ğŸ’¾ Esquema de Datos

### Tabla: `FactTransacciones`
| Columna | Tipo | DescripciÃ³n |
|---------|------|-------------|
| ClienteID | INT | Identificador Ãºnico del cliente |
| Documento | STRING | Documento normalizado (8 dÃ­gitos) |
| NombreCompleto | STRING | Nombre del cliente |
| Fecha | DATE | Fecha de la transacciÃ³n |
| Deposito | DECIMAL(18,2) | Monto total depositado en BolÃ­vares |
| Retiro | DECIMAL(18,2) | Monto total retirado en BolÃ­vares |

---

## ğŸ“ˆ AnÃ¡lisis Disponible

### Queries Ejemplo
```sql
-- Clientes mÃ¡s activos
SELECT NombreCompleto, COUNT(*) as transacciones
FROM FactTransacciones
GROUP BY NombreCompleto
ORDER BY transacciones DESC;

-- Volumen por dÃ­a
SELECT Fecha, SUM(Deposito) as total_depositos, SUM(Retiro) as total_retiros
FROM FactTransacciones
GROUP BY Fecha
ORDER BY Fecha;

-- Balance por cliente
SELECT NombreCompleto, 
       SUM(Deposito) - SUM(Retiro) as balance
FROM FactTransacciones
GROUP BY NombreCompleto;
```

---

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Variables Personalizables
```python
# Rutas de datos
FILE_PATH_TRANSACCIONES = "/Volumes/workspace/proyecto_bancario/datasets/Transacciones.csv"
FILE_PATH_CLIENTES = "/Volumes/workspace/proyecto_bancario/datasets/Clientes.json"

# Esquema destino
TARGET_SCHEMA = "proyecto_bancario"
FACT_TABLE = "FactTransacciones"

# ParÃ¡metros de conversiÃ³n
USD_TO_BOLIVARES = 4.5
```

### Optimizaciones Delta Lake
```python
# VacÃ­o de datos no utilizados
VACUUM proyecto_bancario.FactTransacciones RETAIN 7 DAYS;

# OptimizaciÃ³n de archivos
OPTIMIZE proyecto_bancario.FactTransacciones;
```

---

## ğŸ§ª Testing & ValidaciÃ³n

### Validaciones Implementadas
âœ… Integridad referencial (cliente existe)  
âœ… Tipos de dato correctos  
âœ… ConversiÃ³n de monedas verificada  
âœ… Sin valores nulos en campos clave  
âœ… Fechas dentro de rango vÃ¡lido  

```python
# Validar conteo de registros
assert df_transacciones.count() > 0, "No hay transacciones"
assert df_clientes.count() > 0, "No hay clientes"
assert df.count() == df_transacciones.count(), "PÃ©rdida de datos en JOIN"
```

---

## ğŸ“š DocumentaciÃ³n Adicional

- [Arquitectura Detallada](./docs/ARCHITECTURE.md)
- [Flujo ETL Paso a Paso](./docs/ETL_FLOW.md)
- [SoluciÃ³n de Problemas](./docs/TROUBLESHOOTING.md)
- [DocumentaciÃ³n de Datos](./data/README_DATA.md)

---

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Para cambios importantes:

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

---

## ğŸ“ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

---

## ğŸ‘¨â€ğŸ’» Autor

**Jeysson Leoncio Z.**
Data Engineer | AI Automation Specialist

[LinkedIn](https://www.linkedin.com/in/jeysson-leoncio-z-712661249/) | [GitHub](https://github.com/jeyssonlza)283

---

## ğŸ“ Soporte

Para preguntas o reportar bugs:
- Abre un Issue en GitHub
- Contacta en: [jeyssonzerpa@gmail.com]

---

## ğŸ¯ Roadmap Futuro

- [ ] IntegraciÃ³n con Power BI
- [ ] Alertas automÃ¡ticas de fraude
- [ ] Machine Learning para predicciones
- [ ] API REST para consultas
- [ ] Dashboard interactivo en Databricks SQL
- [ ] AutomatizaciÃ³n con Databricks Jobs

---

**Actualizado**: Enero 2025
